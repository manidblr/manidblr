Create an export dumpfile
Create an S3 bucket

Amazon Resource Name (ARN)
arn:aws:s3:::dbamani29-oradump
s3://dbamani29-oradump


Create AWS Policy: Grant Listbucket, readbucket, writebuket to the policy
arn:aws:iam::473371257295:policy/rds-s3-integration-policy
Reference: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-s3-integration.html
Add ARN and mention "*" in object list to include all the objects.

Create AWS Role:  Assign the policy to the role
arn:aws:iam::473371257295:role/rds-s3-integration-role


Aassociate your IAM role with your DB instance:
Goto RDS: Under "Connectivity & Security Rules", 
"Manage IAM Roles",
Enter "rds-s3-integration-role" in text box, and select the Feature "S3_INTEGRATION"


Configure an option group for Amazon S3 integration:
Select Existing Options Group:
default:oracle-se2-19.     Unable to edit existing Options Group. Hence creating a new one.
Create new group oracle-se2-19-S3 and select S3_INTEGRATION option.


Modify the RDS instance rds-ora1-19c and apply the options group oracle-se2-19-S3 
Upon this change, we will see rdsadmin.rdsadmin_s3_tasks package in RDSADMIN schema that can be used do copy the data from S3.

Downloading files from an Amazon S3 bucket to an Oracle DB instance
SELECT rdsadmin.rdsadmin_s3_tasks.download_from_s3(
      p_bucket_name    =>  'dbamani29-oradump',       
      p_directory_name =>  'DATA_PUMP_DIR') 
   AS TASK_ID FROM DUAL;  
Output Task ID: 1628351568375-28

Below is to download from a specific folder.
SELECT rdsadmin.rdsadmin_s3_tasks.download_from_s3(
      p_bucket_name    =>  'mys3bucket', 
      p_s3_prefix      =>  'myfolder/', 
      p_directory_name =>  'DATA_PUMP_DIR') 
   AS TASK_ID FROM DUAL; 
   
 
 View the result using below query.
 SELECT text FROM table(rdsadmin.rds_file_util.read_text_file('BDUMP','dbtask-1628351568375-28.log')); 

To Do: Verify OEM Agent Option
Verify Upgrade process
Restore from S3.


# Creating tablespace in AWS RDS:
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.Oracle.CommonDBATasks.Database.html
CREATE TABLESPACE USERS_TS DATAFILE SIZE 1G AUTOEXTEND ON MAXSIZE 10G;
This will create a regular tablespace with datafile as below. We dont have to give data file name. Oracle 
/rdsdbdata/db/ORCL_A/datafile/o1_mf_users_ts_jjxkfv5z_.dbf
alert_ORCL.log
db_create_file_dest      = "/rdsdbdata/db"


#Exporting and importing using S3.
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Procedural.Importing.html#Oracle.Procedural.Importing.DataPump.S3
https://oracle-base.com/articles/misc/data-pump-api
https://docs.oracle.com/database/121/ARPLS/d_datpmp.htm#ARPLS66050
https://docs.oracle.com/database/121/ARPLS/d_datpmp.htm#ARPLS66053


Export :
GRANT UNLIMITED TABLESPACE TO "HR"


Import:
Pre-Create the users.
Schemas to import:
HR,OE,SH,IX,PM
EXPORTED_SAMPLE_SCHEMAS.DMP

create user HR identified by "Hello_123" default tablespace USERS_TS;
create user OE identified by "Hello_123" default tablespace USERS_TS;
create user SH identified by "Hello_123" default tablespace USERS_TS;
create user IX identified by "Hello_123" default tablespace USERS_TS;
create user PM identified by "Hello_123" default tablespace USERS_TS;

grant unlimited tablespace, connect, resource to HR;
grant unlimited tablespace, connect, resource to OE;
grant unlimited tablespace, connect, resource to SH;
grant unlimited tablespace, connect, resource to IX;
grant unlimited tablespace, connect, resource to PM;






##DBMS_DATAPUMP.METADATA_FILTER(v_hdnl,'SCHEMA_EXPR','IN (''SCHEMA_1'')');

declare
  l_dp_handle       number;
begin
  -- Open a schema import job.
  l_dp_handle := dbms_datapump.open(
    operation   => 'IMPORT',
    job_mode    => 'SCHEMA',
    remote_link => NULL,
    job_name    => 'TEST_IMPORT1',
    version     => 'LATEST');

  -- Specify the schema to be imported.
  -- dbms_datapump.metadata_filter(
  --   handle => l_dp_handle,
  --   name   => 'SCHEMA_EXPR',
  --   value  => '= ''TESTUSER1''');

  -- Specify the dump file name and directory object name.
  dbms_datapump.add_file(
    handle    => l_dp_handle,
    filename  => 'EXPORTED_SAMPLE_SCHEMAS.DMP',
    directory => 'DATA_PUMP_DIR',
	filetype  => DBMS_DATAPUMP.KU$_FILE_TYPE_DUMP_FILE);
	
	-- filetype  => DBMS_DATAPUMP.KU$_FILE_TYPE_SQL_FILE - For generating a SQL File:

  -- Specify the log file name and directory object name.
  dbms_datapump.add_file(
    handle    => l_dp_handle,
    filename  => 'IMPORT_SAMPLE_SCHEMAS.log',
    directory => 'DATA_PUMP_DIR',
    filetype  => DBMS_DATAPUMP.KU$_FILE_TYPE_LOG_FILE);

  -- Perform a REMAP_SCHEMA from SCOTT to SCOTT2.
  dbms_datapump.metadata_remap(
    handle     => l_dp_handle,
    name       => 'REMAP_TABLESPACE',
    old_value  => 'EXAMPLE',
    value      => 'USERS_TS');

  dbms_datapump.metadata_remap(
    handle     => l_dp_handle,
    name       => 'REMAP_TABLESPACE',
    old_value  => 'USERS',
    value      => 'USERS_TS');
	
  dbms_datapump.set_parallel(
    handle     => l_dp_handle,	
	degree	   => 2);
	
  dbms_datapump.metadata_transform(	
	handle     => l_dp_handle,
	name	   => 'DISABLE_ARCHIVE_LOGGING',
	value	   => 1);
 -- value 1 is disable, and 0 to enable.
 -- object_type is skipped, so ARCHIVING is not done for both Tables & Indexes.
 
  DBMS_DATAPUMP.SET_PARAMETER (
    handle     => l_dp_handle,
	name	   => 'TABLE_EXISTS_ACTION',
	value	   => 'REPLACE');
  
  dbms_datapump.start_job(l_dp_handle);

  dbms_datapump.detach(l_dp_handle);
end;
/



After the data has been imported, you can delete the files that you don't want to keep. You can list the files in the DATA_PUMP_DIR using the following command.

SELECT * FROM TABLE(rdsadmin.rds_file_util.listdir('DATA_PUMP_DIR')) ORDER BY MTIME;

Output:
EXPORTED_SAMPLE_SCHEMAS.DMP	file	59256832	10-AUG-21
IMPORT_SAMPLE_SCHEMAS.log	file	28647	11-AUG-21
datapump/	directory	4096	11-AUG-21


To delete files in the DATA_PUMP_DIR that you no longer require, use the following command.
EXEC UTL_FILE.FREMOVE('DATA_PUMP_DIR','<file name>');
For example, the following command deletes the file named "sample_copied.dmp".

EXEC UTL_FILE.FREMOVE('DATA_PUMP_DIR','sample_copied.dmp'); 

==============================================================================
To Copy from S3 and Vice Versa.
SELECT rdsadmin.rdsadmin_s3_tasks.download_from_s3(
      p_bucket_name    =>  'dbamani29-oradump', 
      p_s3_prefix      =>  'exported_sample_schemas.dmp', 
      p_directory_name =>  'DATA_PUMP_DIR'
--      p_decompress     =>  1 : THis option is still not made available by AWS
      ) 
   AS TASK_ID FROM DUAL;  
SELECT text FROM table(rdsadmin.rds_file_util.read_text_file('BDUMP','1628648503583-40'));    
   
SELECT * FROM TABLE(rdsadmin.rds_file_util.listdir('DATA_PUMP_DIR')) ORDER BY MTIME;

EXEC UTL_FILE.FREMOVE('DATA_PUMP_DIR','exported_sample_schemas.zip'); 

SELECT * FROM TABLE(rdsadmin.rds_file_util.listdir('DATA_PUMP_DIR')) ORDER BY MTIME;


   SELECT rdsadmin.rdsadmin_s3_tasks.upload_to_s3(
      p_bucket_name    =>  'dbamani29-oradump', 
      p_prefix         =>  'exported_sample_schemas.dmp',
      p_s3_prefix      =>  'test2_',
      p_directory_name =>  'DATA_PUMP_DIR'
      --p_compress       => 1 This option is not working.
      ) 
   AS TASK_ID FROM DUAL;
SELECT text FROM table(rdsadmin.rds_file_util.read_text_file('BDUMP','1628648503583-40')); 

===============================================================================================================




Enable JVM to support execution of OS commands:
https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/oracle-options-java.html
db.t3.micro or db.t3.small RDS instances doesn't support JAVA.
Auto Minor Version Upgrade enabled
After Association of JAVAVM options group, grant necessary permissions.

create user test_proc identified by password;
CALL dbms_java.grant_permission('TEST_PROC', 'oracle.aurora.security.JServerPermission', 'LoadClassInPackage.*', ''); 
CALL dbms_java.grant_permission('ADMIN', 'oracle.aurora.security.JServerPermission', 'LoadClassInPackage.*', ''); 
CALL dbms_java.grant_permission('RDSADMIN', 'oracle.aurora.security.JServerPermission', 'LoadClassInPackage.*', ''); 


Running OS commands from SQL/Plus:
https://flylib.com/books/en/2.680.1/running_operating_system_commands.html
